{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08fc5ef-cc6f-48be-93ca-b73ddccc8ec4",
   "metadata": {},
   "source": [
    "# Detect doublets using Scrublet\n",
    "\n",
    "Our cell hashing processes catch and remove many doublets that are generated by mixing of cells from different samples, but some percentage of doublets (~7-8%) will be generated by collisions of cells from the same sample, and will not be detected.\n",
    "\n",
    "To detect and remove these, we'll utilize the Scrublet package. Scrublet's process for doublet identification is described in this publication:\n",
    "\n",
    "Wolock, S. L., Lopez, R. & Klein, A. M. Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Cell Syst 8, 281â€“291.e9 (2019)\n",
    "\n",
    "We'll use scrublet's integration into the scanpy package's [scanpy.external tools](https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.scrublet.html#scanpy.external.pp.scrublet).\n",
    "\n",
    "Here, we apply scrublet to each of our .h5 files, and store the results in HISE for downstream analysis steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae0abc-31d9-483e-8081-8e5c82f8f633",
   "metadata": {},
   "source": [
    "## Load Packages\n",
    "\n",
    "`anndata`: Data structures for scRNA-seq  \n",
    "`concurrent.futures`: parallelization methods  \n",
    "`datetime`: date and time functions  \n",
    "`h5py`: HDF5 file I/O  \n",
    "`hisepy`: The HISE SDK for Python  \n",
    "`numpy`: Mathematical data structures and computation  \n",
    "`os`: operating system calls  \n",
    "`pandas`: DataFrame data structures  \n",
    "`re`: Regular expressions  \n",
    "`scanpy`: scRNA-seq analysis  \n",
    "`scipy.sparse`: Spare matrix data structures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebc2cd4-cc2c-41ac-ab73-e72142c094fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import anndata\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import date\n",
    "import h5py\n",
    "import hisepy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import re\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import scipy.sparse as scs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2862dd-94e1-492d-9718-d7b0d98cbeba",
   "metadata": {},
   "source": [
    "## Read sample metadata from HISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5079642-7422-4031-9a81-3558bc076145",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta_file_uuid = '2da66a1a-17cc-498b-9129-6858cf639caf'\n",
    "file_query = hisepy.reader.read_files(\n",
    "    [sample_meta_file_uuid]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44946c1-2a26-4c9d-9567-ea8212ab2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = file_query['values']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8c51a-b8ee-4c03-b686-67efb98b7753",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "These functions will retrieve data from HISE and read as AnnData for use with scrublet, and for reading and applying scrublet to each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c3aded-0603-4602-a212-790a99ef9c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to read count data\n",
    "def read_mat(h5_con):\n",
    "    mat = scs.csc_matrix(\n",
    "        (h5_con['matrix']['data'][:], # Count values\n",
    "         h5_con['matrix']['indices'][:], # Row indices\n",
    "         h5_con['matrix']['indptr'][:]), # Pointers for column positions\n",
    "        shape = tuple(h5_con['matrix']['shape'][:]) # Matrix dimensions\n",
    "    )\n",
    "    return mat\n",
    "\n",
    "# define a function to read obeservation metadata (i.e. cell metadata)\n",
    "def read_obs(h5con):\n",
    "    bc = h5con['matrix']['barcodes'][:]\n",
    "    bc = [x.decode('UTF-8') for x in bc]\n",
    "\n",
    "    # Initialized the DataFrame with cell barcodes\n",
    "    obs_df = pd.DataFrame({ 'barcodes' : bc })\n",
    "    obs_df = obs_df.set_index('barcodes', drop = False)\n",
    "    obs_df['barcodes'] = obs_df['barcodes'].astype(\"category\")\n",
    "\n",
    "    return obs_df\n",
    "\n",
    "# define a function to construct anndata object from a h5 file\n",
    "def read_h5_anndata(h5_con):\n",
    "    #h5_con = h5py.File(h5_file, mode = 'r')\n",
    "    # extract the expression matrix\n",
    "    mat = read_mat(h5_con)\n",
    "    # extract gene names\n",
    "    genes = h5_con['matrix']['features']['name'][:]\n",
    "    genes = [x.decode('UTF-8') for x in genes]\n",
    "    # extract metadata\n",
    "    obs_df = read_obs(h5_con)\n",
    "    # construct anndata\n",
    "    adata = anndata.AnnData(mat.T,\n",
    "                            obs = obs_df)\n",
    "    # make sure the gene names aligned\n",
    "    adata.var_names = genes\n",
    "\n",
    "    adata.var_names_make_unique()\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f61765-d761-4247-86ff-6a3c608c3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adata(uuid):\n",
    "    # Load the file using HISE\n",
    "    res = hisepy.reader.read_files([uuid])\n",
    "\n",
    "    # If there's an error, read_files returns a list instead of a dictionary.\n",
    "    # We should raise and exception with the message when this happens.\n",
    "    if(isinstance(res, list)):\n",
    "        error_message = res[0]['message']\n",
    "        raise Exception(error_message)\n",
    "    \n",
    "    # Read the file to adata\n",
    "    h5_con = res['values'][0]\n",
    "    adata = read_h5_anndata(h5_con)\n",
    "    \n",
    "    # Clean up the file now that we're done with it\n",
    "    h5_file = h5_con.filename\n",
    "    h5_con.close()\n",
    "    os.remove(h5_file)\n",
    "\n",
    "    return(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616e22b5-e5a0-4dd1-8417-746d35f72eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_file(file_uuid):\n",
    "    adata = get_adata(file_uuid)\n",
    "    sc.external.pp.scrublet(adata, verbose = False)\n",
    "    result = adata.obs[['barcodes','predicted_doublet','doublet_score']]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a10e0-ec49-485a-9ebb-06e0f76fb8ff",
   "metadata": {},
   "source": [
    "## Apply to each sample in parallel\n",
    "\n",
    "Here, we'll use `concurrent.futures` to apply the function above to our samples in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d334e1a-a13c-41d2-9107-ec3e2fa4e490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "file_uuids = meta_data['file.id'].tolist()\n",
    "with ThreadPoolExecutor(max_workers = 20) as executor:  \n",
    "    for result in executor.map(process_file, file_uuids):\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d06af9-9857-4a99-88ce-83c0a1d99654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_result = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f7adfb-8481-45aa-a729-5c196ee0c728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_doublet\n",
       "False    2055549\n",
       "True       27205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_counts = final_result['predicted_doublet'].value_counts()\n",
    "prediction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f934524-85d3-4662-a671-ff4ab7c9cbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013062032289939187"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_counts[1] / sum(prediction_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beebca5-fc7d-4be8-9d9a-938ec6aa6abd",
   "metadata": {},
   "source": [
    "## Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5a2914-f319-40a6-85c7-48d0c2cfa779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_dir = 'output'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53bb1f48-d0bc-41d4-a906-0c6ebc18568d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_file = 'output/ref_scrublet_results_{d}.csv'.format(d = date.today())\n",
    "final_result.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e34309-e898-49d6-bce1-5afcae065748",
   "metadata": {},
   "source": [
    "## Upload assembled data to HISE\n",
    "\n",
    "Finally, we'll use `hisepy.upload.upload_files()` to send a copy of our output to HISE to use for downstream analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee59a238-6093-47f4-8a88-1c389a4c788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_space_uuid = '64097865-486d-43b3-8f94-74994e0a72e0'\n",
    "title = 'Reference Scrublet results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47a49d96-16b9-4122-98a8-1c103d1f55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files = [sample_meta_file_uuid] + meta_data['file.id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f96ed0f-036e-4700-ad4d-b93fa6155cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files = [out_file]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0607187-e595-4481-b0c1-48b754f7101a",
   "metadata": {},
   "source": [
    "hisepy.upload.upload_files(\n",
    "    files = out_files,\n",
    "    study_space_id = study_space_uuid,\n",
    "    title = title,\n",
    "    input_file_ids = in_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4af83-9148-4c73-a229-274fcf777fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
