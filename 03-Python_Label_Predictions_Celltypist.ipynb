{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e588eade-1a0b-4475-b64f-e34872402893",
   "metadata": {},
   "source": [
    "# Label cell types using CellTypist Models\n",
    "\n",
    "To build our reference, we would like to start with labels that originate from published cell type references. \n",
    "\n",
    "One of the approaches for this cell type labeling is CellTypist, a model-based approach to cell type labeling.  \n",
    "\n",
    "CellTypist is described [on their website](https://www.celltypist.org/), and in this publication:  \n",
    "\n",
    "Domínguez Conde, C. et al. Cross-tissue immune cell analysis reveals tissue-specific features in humans. Science 376, eabl5197 (2022)\n",
    "\n",
    "Here, we'll load in our cells in batches, and assign cell types based on 3 available CellTypist models (descriptions are from celltypist.org):  \n",
    "\n",
    "- Immune_All_High:\n",
    "    - 32 types\n",
    "    - immune populations combined from 20 tissues of 18 studies  \n",
    "- Immune_All_Low:  \n",
    "    - 98 types\n",
    "    - immune sub-populations combined from 20 tissues of 18 studies  \n",
    "- Healthy_COVID19_PBMC:\n",
    "    - 51 types\n",
    "    - peripheral blood mononuclear cell types from healthy and COVID-19 individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a83eb8-37dd-49ad-9670-fff2365d5d13",
   "metadata": {},
   "source": [
    "## Load Packages\n",
    "\n",
    "anndata: Data structures for scRNA-seq  \n",
    "celltypist: Model-based cell type annotation  \n",
    "concurrent.futures: parallelization methods  \n",
    "datetime: date and time functions  \n",
    "h5py: HDF5 file I/O  \n",
    "hisepy: The HISE SDK for Python  \n",
    "numpy: Mathematical data structures and computation  \n",
    "os: operating system calls  \n",
    "pandas: DataFrame data structures  \n",
    "re: Regular expressions  \n",
    "scanpy: scRNA-seq analysis  \n",
    "scipy.sparse: Spare matrix data structures  \n",
    "shutil: Shell utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf3c687-3777-495f-8a9a-39e1e65fd449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import anndata\n",
    "import celltypist\n",
    "from celltypist import models\n",
    "import concurrent.futures\n",
    "from datetime import date\n",
    "import h5py\n",
    "import hisepy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import re\n",
    "import scanpy as sc\n",
    "import scipy.sparse as scs\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd8976-9454-49e0-932f-e8a13dd8c768",
   "metadata": {},
   "source": [
    "## Obtain CellTypist Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de69a63-45c8-40f4-aef7-738830d82e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📜 Retrieving model list from server https://celltypist.cog.sanger.ac.uk/models/models.json\n",
      "📚 Total models in list: 44\n",
      "📂 Storing models in /root/.celltypist/data/models\n",
      "💾 Total models to download: 3\n",
      "💾 Downloading model [1/3]: Immune_All_Low.pkl\n",
      "💾 Downloading model [2/3]: Immune_All_High.pkl\n",
      "💾 Downloading model [3/3]: Healthy_COVID19_PBMC.pkl\n"
     ]
    }
   ],
   "source": [
    "models.download_models(\n",
    "    force_update = True,\n",
    "    model = ['Immune_All_High.pkl',\n",
    "             'Immune_All_Low.pkl',\n",
    "             'Healthy_COVID19_PBMC.pkl']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4a141-780e-4eab-b9c1-d7b5865dfabd",
   "metadata": {},
   "source": [
    "## Read sample metadata from HISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f55a5a2-a5e0-42ce-a34c-9add7cbef948",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta_file_uuid = '223b4aa9-19fc-41e1-8bea-43682e5ac278'\n",
    "sample_meta_file_name = 'ref_h5_meta_data_2024-02-08.csv'\n",
    "file_query = hisepy.reader.download_files(\n",
    "    {sample_meta_file_uuid: sample_meta_file_name}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23e68326-f5e9-4925-8926-5d8545bc26af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': UUID('223b4aa9-19fc-41e1-8bea-43682e5ac278'),\n",
       " 'status': False,\n",
       " 'message': 'File was not found in ledger',\n",
       " 'descriptors': None,\n",
       " 'path': None,\n",
       " 'filetype': None,\n",
       " 'data_values': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_query[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21ce05a3-f4dc-4475-923a-f7049b833326",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta_file = 'cache/downloadable/' + sample_meta_file_name\n",
    "meta_data = pd.read_csv(sample_meta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bbcac-82f0-4c06-b295-5655c85c0c96",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "These functions will retrieve data for a batch of samples, assemble a joint AnnData object, perform normalization and log transformation, then generate predictions for each of the 3 models retrieved, above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a81ae7c-7930-4b56-a3b2-0f6cbfe711c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to read count data\n",
    "def read_mat(h5_con):\n",
    "    mat = scs.csc_matrix(\n",
    "        (h5_con['matrix']['data'][:], # Count values\n",
    "         h5_con['matrix']['indices'][:], # Row indices\n",
    "         h5_con['matrix']['indptr'][:]), # Pointers for column positions\n",
    "        shape = tuple(h5_con['matrix']['shape'][:]) # Matrix dimensions\n",
    "    )\n",
    "    return mat\n",
    "\n",
    "# define a function to read obeservation metadata (i.e. cell metadata)\n",
    "def read_obs(h5con):\n",
    "    bc = h5con['matrix']['barcodes'][:]\n",
    "    bc = [x.decode('UTF-8') for x in bc]\n",
    "\n",
    "    # Initialized the DataFrame with cell barcodes\n",
    "    obs_df = pd.DataFrame({ 'barcodes' : bc })\n",
    "\n",
    "    # Get the list of available metadata columns\n",
    "    obs_columns = h5con['matrix']['observations'].keys()\n",
    "\n",
    "    # For each column\n",
    "    for col in obs_columns:\n",
    "        # Read the values\n",
    "        values = h5con['matrix']['observations'][col][:]\n",
    "        # Check for byte storage\n",
    "        if(isinstance(values[0], (bytes, bytearray))):\n",
    "            # Decode byte strings\n",
    "            values = [x.decode('UTF-8') for x in values]\n",
    "        # Add column to the DataFrame\n",
    "        obs_df[col] = values\n",
    "\n",
    "    obs_df = obs_df.set_index('barcodes', drop = False)\n",
    "    \n",
    "    return obs_df\n",
    "\n",
    "# define a function to construct anndata object from a h5 file\n",
    "def read_h5_anndata(h5_con):\n",
    "    #h5_con = h5py.File(h5_file, mode = 'r')\n",
    "    # extract the expression matrix\n",
    "    mat = read_mat(h5_con)\n",
    "    # extract gene names\n",
    "    genes = h5_con['matrix']['features']['name'][:]\n",
    "    genes = [x.decode('UTF-8') for x in genes]\n",
    "    # extract metadata\n",
    "    obs_df = read_obs(h5_con)\n",
    "    # construct anndata\n",
    "    adata = anndata.AnnData(mat.T,\n",
    "                             obs = obs_df)\n",
    "    # make sure the gene names aligned\n",
    "    adata.var_names = genes\n",
    "\n",
    "    adata.var_names_make_unique()\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbb3440-41ca-4942-850d-1ad053da164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adata(uuid):\n",
    "    # Load the file using HISE\n",
    "    res = hisepy.reader.read_files([uuid])\n",
    "\n",
    "    # If there's an error, read_files returns a list instead of a dictionary.\n",
    "    # We should raise and exception with the message when this happens.\n",
    "    if(isinstance(res, list)):\n",
    "        error_message = res[0]['message']\n",
    "        raise Exception(error_message)\n",
    "    \n",
    "    # Read the file to adata\n",
    "    h5_con = res['values'][0]\n",
    "    adata = read_h5_anndata(h5_con)\n",
    "    \n",
    "    # Clean up the file now that we're done with it\n",
    "    h5_file = h5_con.filename\n",
    "    h5_con.close()\n",
    "    os.remove(h5_file)\n",
    "\n",
    "    return(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcd92d2-af9e-4e6f-8f51-450796d40476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(adata, model, model_name, out_dir = \"output\"):\n",
    "    # Perform prediction\n",
    "    predictions = celltypist.annotate(\n",
    "        adata, \n",
    "        model = model, \n",
    "        majority_voting = True)\n",
    "\n",
    "    # Make output directory\n",
    "    model_dir = \"{d}/{m}\".format(d = out_dir, m = model_name)\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Write output per sample\n",
    "    samples = adata.obs['pbmc_sample_id'].unique()\n",
    "    for sample_id in samples:\n",
    "        barcodes = adata.obs[adata.obs['pbmc_sample_id'] == sample_id].index.tolist()\n",
    "        sample_results = predictions.predicted_labels.loc[barcodes,:]\n",
    "        out_file = \"{d}/{s}_{m}.csv\".format(d = model_dir, s = sample_id, m = model_name)\n",
    "        sample_results.to_csv(out_file)\n",
    "\n",
    "def process_data(meta_data_sub):\n",
    "    out_dir = \"output\"\n",
    "    \n",
    "    # Load cells from HISE .h5 files\n",
    "    results = []\n",
    "    for file_uuid in meta_data_sub:\n",
    "        result = get_adata(file_uuid)\n",
    "        results.append(result)\n",
    "    adata = anndata.concat(results)\n",
    "    del results\n",
    "    \n",
    "    # Normalize data\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.obs.index = adata.obs['barcodes']\n",
    "    \n",
    "    # Predict cell types\n",
    "    run_prediction(adata, \"Immune_All_Low.pkl\", \"Low\", out_dir)\n",
    "    run_prediction(adata, \"Immune_All_High.pkl\", \"High\", out_dir)\n",
    "    run_prediction(adata, \"Healthy_COVID19_PBMC.pkl\", \"Covid_Healthy\", out_dir)\n",
    "    \n",
    "    del adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79d0ec-ec3a-4644-a149-a3058255904f",
   "metadata": {},
   "source": [
    "## Apply across batches\n",
    "\n",
    "Here, we'll generate the batches, then use `concurrent.futures` to apply the function above to our batches in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e28d2e7-a974-4721-8d86-ff79605aa155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_dir = 'output'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de4c140e-5ff1-45e4-9393-dd636d9a7eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_data_subsets = []\n",
    "for i in range(0, len(meta_data), 10):\n",
    "    subset_uuids = meta_data[\"file.id\"][i:i + 10]\n",
    "    meta_data_subsets.append(subset_uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06510b9e-62f9-4fd9-812c-5f94603b3b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 156449 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "🔬 Input data has 179276 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 173666 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🔬 Input data has 193957 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🔬 Input data has 187700 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 199483 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 200104 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 207788 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 187235 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 198214 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🔬 Input data has 209206 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "🖋️ Predicting labels\n",
      "🖋️ Predicting labels\n",
      "🖋️ Predicting labels\n",
      "🖋️ Predicting labels\n",
      "🖋️ Predicting labels\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "✅ Prediction done!\n",
      "👀 Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 156449 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 187235 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 187700 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 198214 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 209206 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 200104 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 179276 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🖋️ Predicting labels\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 173666 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 156449 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 187235 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 207788 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 199483 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 193957 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 5967 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 187700 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 198214 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 209206 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 200104 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 179276 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 173666 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 207788 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 30\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 199483 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🔬 Input data has 193957 cells and 33538 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3443 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "👀 Detected a neighborhood graph in the input object, will run over-clustering on the basis of it\n",
      "⛓️ Over-clustering input data with resolution set to 25\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n",
      "🗳️ Majority voting the predictions\n",
      "✅ Majority voting done!\n"
     ]
    }
   ],
   "source": [
    "# Process each subset in parallel\n",
    "pool_executor = concurrent.futures.ProcessPoolExecutor(max_workers = 11)\n",
    "with pool_executor as executor:\n",
    "    \n",
    "    futures = []\n",
    "    for meta_data_sub in meta_data_subsets:\n",
    "        futures.append(executor.submit(process_data, meta_data_sub))\n",
    "\n",
    "    # Check for errors when parallel processes return results\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db89fd-2f92-4148-9a6d-f115c1efe52e",
   "metadata": {},
   "source": [
    "## Assemble results\n",
    "\n",
    "For each model, we'll assemble the results as a .csv file that we can utilize later for subclustering and analysis of major cell classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa2c2832-1f92-4830-95c1-b87d44c6e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['High', 'Low', 'Covid_Healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "942b3d87-2fbb-461d-8f04-89c13118d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files = []\n",
    "for model in models:\n",
    "    model_path = 'output/{m}'.format(m = model)\n",
    "    model_files = os.listdir(model_path)\n",
    "    model_list = []\n",
    "    for model_file in model_files:\n",
    "        df = pd.read_csv('output/{m}/{f}'.format(m = model, f = model_file))\n",
    "        model_list.append(df)\n",
    "    model_df = pd.concat(model_list)\n",
    "\n",
    "    out_file = 'output/ref_celltypist_labels_{m}_{d}.csv'.format(m = model, d = date.today())\n",
    "    out_files.append(out_file)\n",
    "    \n",
    "    model_df.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd746b1-8066-44a5-8613-f401e6fce07e",
   "metadata": {},
   "source": [
    "## Upload assembled data to HISE\n",
    "\n",
    "Finally, we'll use `hisepy.upload.upload_files()` to send a copy of our output to HISE to use for downstream analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ded63cd-7268-4c1c-8ce8-bc466dbd937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function upload_files in module hisepy.upload:\n",
      "\n",
      "upload_files(files: list, study_space_id: str = None, project: str = None, title: str = None, input_file_ids=None, input_sample_ids=None, file_types=None, store=None, destination=None, do_prompt: bool = True)\n",
      "    Uploads files to a specified study.\n",
      "    \n",
      "    Parameters:\n",
      "        files (list): absolute filepath of file to be uploaded\n",
      "        study_space_id (str): ID that pertains to a study in the collaboration space (optional)\n",
      "        project (str): project short name (required if study space is not specified)\n",
      "        title (str): 10+ character title for upload result \n",
      "        input_file_ids (list): fileIds from HISE that were utilized to generate a user's result\n",
      "        input_sample_ids (list): sampleIds from HISE that were utilized to generate a user's result\n",
      "        file_types (str): filetype of uploaded files \n",
      "        store (str): Which store ('project' or 'permanent') to use for the files (default in 'project')\n",
      "        destination (str): Destination folder for the files \n",
      "        do_prompt (bool): whether or not to prompt for user's input, asking to proceed.\n",
      "    Returns: \n",
      "        dictionary with keys [\"trace_id\", \"files\"]\n",
      "    Example: \n",
      "        hp.upload_files(files=['/home/jupyter/upload_file.csv'],\n",
      "                        study_space_id='f2f03ecb-5a1d-4995-8db9-56bd18a36aba',\n",
      "                        title='a upload title',\n",
      "                        input_file_ids=['9f6d7ab5-1c7b-4709-9455-3d8ffffbb6c8'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hisepy.upload.upload_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66e3e599-872c-4677-8bee-08d04003958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_space_uuid = '64097865-486d-43b3-8f94-74994e0a72e0'\n",
    "title = 'Reference CellTypist label predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bffe38f-4223-4919-b46a-a4b8536dde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files = [sample_meta_file_uuid] + meta_data['file.id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80a524b6-7c4c-48c1-8b8c-d05494737bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The following file Ids were not downloaded in this IDE. You cannot reference a file in a result without downloading it first. ['223b4aa9-19fc-41e1-8bea-43682e5ac278']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhisepy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_space_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstudy_space_uuid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_file_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_files\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/hisepy-0.3.0-py3.10.egg/hisepy/upload.py:166\u001b[0m, in \u001b[0;36mupload_files\u001b[0;34m(files, study_space_id, project, title, input_file_ids, input_sample_ids, file_types, store, destination, do_prompt)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(files) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files specified for upload\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m \u001b[43mcu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_upload_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sample_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m validate_upload_data(study_space_id, project, title, input_file_ids)\n\u001b[1;32m    168\u001b[0m uploads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/hisepy-0.3.0-py3.10.egg/hisepy/common_utils.py:190\u001b[0m, in \u001b[0;36mvalidate_upload_input_ids\u001b[0;34m(input_file_ids, input_sample_ids)\u001b[0m\n\u001b[1;32m    187\u001b[0m         invalid_sample_ids \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [s]\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(invalid_file_ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following file Ids were not downloaded in this IDE. You cannot reference a file in a result without downloading it first. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(invalid_file_ids))\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(invalid_sample_ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following sample Ids were not downloaded in this IDE. You cannot refernce a file in a result without downloading it first. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(invalid_sample_ids))\n",
      "\u001b[0;31mAssertionError\u001b[0m: The following file Ids were not downloaded in this IDE. You cannot reference a file in a result without downloading it first. ['223b4aa9-19fc-41e1-8bea-43682e5ac278']"
     ]
    }
   ],
   "source": [
    "hisepy.upload.upload_files(\n",
    "    files = out_files,\n",
    "    study_space_id = study_space_uuid,\n",
    "    title = title,\n",
    "    input_file_ids = in_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b33023-1c16-46c1-9e7c-8a38e1dd9862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df57b01-3914-48ae-9cc2-f03faec7473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6adf5-66cf-4dbc-b17a-1a7cf6c0bb06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
